{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Download necessary NLP resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_description(row):\n",
    "    description_parts = []\n",
    "    \n",
    "    # Add parts only if the column has a value (i.e., not empty or NaN)\n",
    "    description_parts.append(\"indicator\")\n",
    "    if pd.notna(row[2]) and row[2] != \"\":\n",
    "        description_parts.append(str(row[2]) + \" movement\")\n",
    "    if pd.notna(row[9]) and row[9] != \"\":\n",
    "        description_parts.append(str(row[9]))\n",
    "    if pd.notna(row[18]) and row[18] != \"\":\n",
    "        description_parts.append(str(row[18]))\n",
    "    if pd.notna(row[11]) and row[11] != \"\":\n",
    "        description_parts.append(str(row[11]))\n",
    "    if pd.notna(row[10]) and row[10] != \"\":\n",
    "        description_parts.append(str(row[10]))\n",
    "    description_parts.append(\"electric indicator\")\n",
    "    if pd.notna(row[5]) and row[5] != \"\":\n",
    "        description_parts.append(str(row[5])+ \" blow\")\n",
    "    if pd.notna(row[28]) and row[28] != \"\":\n",
    "        description_parts.append(str(row[28]))\n",
    "    if pd.notna(row[30]) and row[30] != \"\":\n",
    "        description_parts.append(str(row[30])+ \"ac \")\n",
    "    if pd.notna(row[27]) and row[27] != \"\":\n",
    "        description_parts.append(str(row[27])+ \" ir\")\n",
    "    if pd.notna(row[19]) and row[19] != \"\":\n",
    "        description_parts.append(str(row[19]))\n",
    "    if pd.notna(row[11]) and row[11] != \"\":\n",
    "        description_parts.append(str(row[11]))\n",
    "    \n",
    "    # Join the parts with a space, and return the result\n",
    "    return \" \".join(description_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Dell\\Desktop\\bmw-tasks\\Parts.csv\", encoding=\"utf-8\", delimiter=\";\")\n",
    "# df.to_csv(r\"C:\\Users\\Dell\\Desktop\\bmw-tasks\\Parts_fixed_original.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5044\\129838707.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5044\\129838707.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df.iloc[:, 1] = df.apply(lambda row: create_description(row) if pd.isna(row[1]) or row[1] == \"\" else row[1], axis=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#convert all string values to lowercase\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x) \n",
    "\n",
    "# Remove '|' , ',' and '/' from all columns\n",
    "df = df.replace(r\"[|/,()]\", \"\", regex=True)\n",
    "\n",
    "# Apply the function to fill missing descriptions in column 2\n",
    "df.iloc[:, 1] = df.apply(lambda row: create_description(row) if pd.isna(row[1]) or row[1] == \"\" else row[1], axis=1)\n",
    "\n",
    "# Replace the description in column 2 if it matches the specified string\n",
    "df.iloc[:, 1] = df.iloc[:, 1].replace(\"indicator electric indicator\", \"unknown part\")\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\Dell\\Desktop\\bmw-tasks\\Parts_fixed.csv\", index=False, encoding=\"utf-8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"DESCRIPTION\"])\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search completed. Results saved!\n"
     ]
    }
   ],
   "source": [
    "# Find 5 most similar parts\n",
    "def find_similar_parts(index, cosine_sim=cosine_sim, top_n=5):\n",
    "    sim_scores = list(enumerate(cosine_sim[index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]  # Exclude self\n",
    "    similar_indices = [i[0] for i in sim_scores]\n",
    "    similar_parts = df.iloc[similar_indices][[\"ID\", \"DESCRIPTION\"]]\n",
    "    return similar_parts.values.tolist()\n",
    "\n",
    "# Create similarity mapping\n",
    "df[\"SIMILAR_PARTS\"] = df.index.map(lambda i: find_similar_parts(i))\n",
    "\n",
    "# Save results\n",
    "df.to_csv(\"Parts_with_similarities.csv\", index=False)\n",
    "print(\"Similarity search completed. Results saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (jupyter_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
